{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datathon FME 2022 : The Accenture Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "The code presented in this notebook is the result of the work of the @Shambala team composed of : \n",
    "\n",
    "- Walid Ider\n",
    "- Marie Mayol\n",
    "- Yannig Delorme \n",
    "\n",
    "During the 2nd Edition of the FME Datathon that took place in the UPC School of Mathematics and Statistics\n",
    "\n",
    "This Datathon was also a part of the seminars of the SIRI-MIRI course of the Barcelona School of Informatics\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject and context : \n",
    "\n",
    "- Understanding main root-cause affecting supply chain deliveries and predicting product delays based on historical inbound/outbound orders of the company.\n",
    "- Providing visibility of supply chain resiliency to maximize customer service levels.\n",
    "\n",
    "##### What is it expected from the technical challenge?\n",
    "\n",
    "- Provide data insights based on descriptive analytics of historical data.\n",
    "- Predictive model to predict likelihood of order delay. The metric to evaluate models will be AUC (ROC), you must submit a predicted likelihood between 0 and 1 for the True class.\n",
    "\n",
    "The data available will be four .csv files, containing various informations about the orders, products, and cities of shipment, as well as a testing file.\n",
    "\n",
    "The submission will be then, done on Kaggle.\n",
    "\n",
    "The results of this work were presented in front of a jury on the 13th November 2022.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import itertools as it\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import typing\n",
    "from typing import Optional, Union, Tuple\n",
    "import logging\n",
    "import tqdm\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import  mean_absolute_error, mean_squared_error\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Data Preprocessing and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data : \n",
    "\n",
    "#path = \"datathonfme2022-main/accenture_challenge/datathon_SC_ACN_22/\"\n",
    "path=\"\"\n",
    "\n",
    "for x in [\"cities_data\",\"orders\",\"test\"] : \n",
    "    locals()[x] = pd.read_csv(path + x + \".csv\",sep=\";\")\n",
    "product_attributes = pd.read_csv(path + \"product_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>origin_port</th>\n",
       "      <th>3pl</th>\n",
       "      <th>customs_procedures</th>\n",
       "      <th>logistic_hub</th>\n",
       "      <th>customer</th>\n",
       "      <th>product_id</th>\n",
       "      <th>units</th>\n",
       "      <th>late_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366c7a3d298f</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>DTP</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>1692723</td>\n",
       "      <td>583</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45f906331e10</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_004</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>1644308</td>\n",
       "      <td>459</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ac84a6e4af0f</td>\n",
       "      <td>Athens</td>\n",
       "      <td>v_002</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1684170</td>\n",
       "      <td>464</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f5e98cb29790</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_004</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Milan</td>\n",
       "      <td>1620510</td>\n",
       "      <td>678</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a9e7c9bee35b</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>v_002</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1699372</td>\n",
       "      <td>353</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114271</th>\n",
       "      <td>3f4b15fb770e</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>1681376</td>\n",
       "      <td>645</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114272</th>\n",
       "      <td>d2e6978a38fd</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>v_004</td>\n",
       "      <td>DTD</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1676942</td>\n",
       "      <td>502</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114273</th>\n",
       "      <td>b88babd5c7bd</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>DTP</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Rome</td>\n",
       "      <td>1692737</td>\n",
       "      <td>464</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114274</th>\n",
       "      <td>b0b5c761613f</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>v_003</td>\n",
       "      <td>DTD</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Munich</td>\n",
       "      <td>1699974</td>\n",
       "      <td>388</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114275</th>\n",
       "      <td>1ab8e51519e4</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>DTD</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Bucharest</td>\n",
       "      <td>1620510</td>\n",
       "      <td>482</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114276 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id origin_port    3pl customs_procedures logistic_hub  \\\n",
       "0       366c7a3d298f   Rotterdam  v_002                DTP        Venlo   \n",
       "1       45f906331e10   Rotterdam  v_004                CRF         Rome   \n",
       "2       ac84a6e4af0f      Athens  v_002                CRF        Venlo   \n",
       "3       f5e98cb29790   Rotterdam  v_004                CRF        Lille   \n",
       "4       a9e7c9bee35b   Barcelona  v_002                CRF        Venlo   \n",
       "...              ...         ...    ...                ...          ...   \n",
       "114271  3f4b15fb770e   Rotterdam  v_002                CRF   Dusseldorf   \n",
       "114272  d2e6978a38fd   Barcelona  v_004                DTD   Dusseldorf   \n",
       "114273  b88babd5c7bd   Rotterdam  v_002                DTP   Dusseldorf   \n",
       "114274  b0b5c761613f   Barcelona  v_003                DTD   Dusseldorf   \n",
       "114275  1ab8e51519e4   Rotterdam  v_002                DTD        Venlo   \n",
       "\n",
       "         customer  product_id  units  late_order  \n",
       "0       Marseille     1692723    583        True  \n",
       "1       Marseille     1644308    459       False  \n",
       "2           Paris     1684170    464        True  \n",
       "3           Milan     1620510    678       False  \n",
       "4          Berlin     1699372    353       False  \n",
       "...           ...         ...    ...         ...  \n",
       "114271   Bordeaux     1681376    645       False  \n",
       "114272     Berlin     1676942    502       False  \n",
       "114273       Rome     1692737    464       False  \n",
       "114274     Munich     1699974    388       False  \n",
       "114275  Bucharest     1620510    482       False  \n",
       "\n",
       "[114276 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>material_handling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.720000e+02</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.682036e+06</td>\n",
       "      <td>1303.297927</td>\n",
       "      <td>3.164508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.723441e+04</td>\n",
       "      <td>526.166950</td>\n",
       "      <td>1.707581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.613321e+06</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.671913e+06</td>\n",
       "      <td>937.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.685214e+06</td>\n",
       "      <td>1292.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.696982e+06</td>\n",
       "      <td>1659.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.702654e+06</td>\n",
       "      <td>2876.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id       weight  material_handling\n",
       "count  7.720000e+02   772.000000         772.000000\n",
       "mean   1.682036e+06  1303.297927           3.164508\n",
       "std    1.723441e+04   526.166950           1.707581\n",
       "min    1.613321e+06   136.000000           0.000000\n",
       "25%    1.671913e+06   937.500000           2.000000\n",
       "50%    1.685214e+06  1292.500000           3.000000\n",
       "75%    1.696982e+06  1659.500000           5.000000\n",
       "max    1.702654e+06  2876.000000           5.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_attributes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A good idea to check the statistical distribution of a variable is to verify a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "product_attributes.drop(columns=[\"product_id\",\"material_handling\"]).boxplot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at a histogram for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'False vs True'}>]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp=pd.DataFrame([1 if x==True else 0 for x in orders[\"late_order\"]])\n",
    "df_tmp.rename(columns={0 : \"False vs True\"},inplace=True)\n",
    "df_tmp.hist(bins=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our strategy will be to unify our three datasets in an intuitive way. We believe that whether an order is late or not depends principally, regarding the two datasets other than \"orders.csv\", on the distance between the shipment base and the destination, as well as the weight and fragility of the materials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding distances \n",
    "data = orders.copy()\n",
    "\n",
    "distance_origin_hub= []\n",
    "distance_hub_customer = []\n",
    "\n",
    "for i in range(len(data)): \n",
    "    try : \n",
    "        distance_origin_hub.append(float(cities_data[(cities_data[\"city_from_name\"] == data[\"origin_port\"][i])& (cities_data[\"city_to_name\"] == data[\"logistic_hub\"][i])][\"distance\"]))\n",
    "    except:\n",
    "        distance_origin_hub.append(np.nan)\n",
    "    try : \n",
    "        distance_hub_customer.append(float(cities_data[(cities_data[\"city_from_name\"] == data[\"logistic_hub\"][i] )& (cities_data[\"city_to_name\"] == data[\"customer\"][i])][\"distance\"]))\n",
    "    except:\n",
    "        distance_hub_customer.append(np.nan)\n",
    "        \n",
    "data[\"distance_origin_hub\"]=distance_origin_hub\n",
    "data[\"distance_hub_customer\"] = distance_hub_customer       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.join(product_attributes.set_index(\"product_id\"), on = \"product_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also try to check the percentage of late orders beforehand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of late orders : 23.76 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of late orders : \" + str(round((len(orders[orders[\"late_order\"]==True])/len(orders))*100,2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have a lot of string values in our dataset, which is not friendly to some classification algorithms we are going to be using. Therefore, we are going to use a label encoder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MassLabelEncoding(df) : \n",
    "    \"\"\"\n",
    "    Label Encoding on all string columns \n",
    "    of a non-empty DataFrame\n",
    "    \"\"\"\n",
    "    le=LabelEncoder()\n",
    "    firstRow = list(df.iloc[0])\n",
    "    for i in range(len(firstRow)) : \n",
    "        if type(firstRow[i]) == str : \n",
    "            currentColumn = list(df.columns)[i]\n",
    "            df[currentColumn] = le.fit_transform(df[currentColumn])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition to that, many cities are represented twice, in another form, such as : \"BCN\" for \"Barcelona\" est...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([\"BCN\",\"ATHENAS\"],[\"Barcelona\", \"Athens\"],inplace=True) #Replacing double values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given the fact that we are dealing with real values such as distances between cities, imputing a value in whatever strategy (mean, median, most_frequent...) would be irrelevant. Thus, we are going to drop for now the empty values from our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True) # removing all values, imputing values here would be irrelevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One quick look to a correlation clustermap before moving to the next part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustermap=0 # put =1 to visualise clustermap\n",
    "if clustermap==1:\n",
    "    sns.cluster(np.array(data.drop(columns=[\"origin_port\" , \"order_id\" , \"logistic_hub\" , \"customer\", \"late_order\", \"3pl\", \"customs_procedures\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>units</th>\n",
       "      <th>distance_origin_hub</th>\n",
       "      <th>distance_hub_customer</th>\n",
       "      <th>weight</th>\n",
       "      <th>material_handling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1692723</td>\n",
       "      <td>583</td>\n",
       "      <td>130.0459</td>\n",
       "      <td>902.0420</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1644308</td>\n",
       "      <td>459</td>\n",
       "      <td>1269.2365</td>\n",
       "      <td>604.0216</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1620510</td>\n",
       "      <td>678</td>\n",
       "      <td>173.9644</td>\n",
       "      <td>733.8784</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1699793</td>\n",
       "      <td>609</td>\n",
       "      <td>1269.2365</td>\n",
       "      <td>477.3222</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1699836</td>\n",
       "      <td>465</td>\n",
       "      <td>130.0459</td>\n",
       "      <td>1436.9241</td>\n",
       "      <td>445.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114266</th>\n",
       "      <td>1674120</td>\n",
       "      <td>410</td>\n",
       "      <td>414.4489</td>\n",
       "      <td>901.2353</td>\n",
       "      <td>932.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114270</th>\n",
       "      <td>1699689</td>\n",
       "      <td>695</td>\n",
       "      <td>1135.6449</td>\n",
       "      <td>816.0497</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114271</th>\n",
       "      <td>1681376</td>\n",
       "      <td>645</td>\n",
       "      <td>177.3075</td>\n",
       "      <td>896.2065</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114273</th>\n",
       "      <td>1692737</td>\n",
       "      <td>464</td>\n",
       "      <td>177.3075</td>\n",
       "      <td>1125.0290</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114275</th>\n",
       "      <td>1620510</td>\n",
       "      <td>482</td>\n",
       "      <td>130.0459</td>\n",
       "      <td>1672.4754</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63336 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_id  units  distance_origin_hub  distance_hub_customer  weight  \\\n",
       "0          1692723    583             130.0459               902.0420  1778.0   \n",
       "1          1644308    459            1269.2365               604.0216  1088.0   \n",
       "3          1620510    678             173.9644               733.8784  1308.0   \n",
       "6          1699793    609            1269.2365               477.3222  2400.0   \n",
       "9          1699836    465             130.0459              1436.9241   445.0   \n",
       "...            ...    ...                  ...                    ...     ...   \n",
       "114266     1674120    410             414.4489               901.2353   932.0   \n",
       "114270     1699689    695            1135.6449               816.0497  2369.0   \n",
       "114271     1681376    645             177.3075               896.2065  1896.0   \n",
       "114273     1692737    464             177.3075              1125.0290   572.0   \n",
       "114275     1620510    482             130.0459              1672.4754  1308.0   \n",
       "\n",
       "        material_handling  \n",
       "0                     5.0  \n",
       "1                     3.0  \n",
       "3                     4.0  \n",
       "6                     2.0  \n",
       "9                     3.0  \n",
       "...                   ...  \n",
       "114266                5.0  \n",
       "114270                0.0  \n",
       "114271                3.0  \n",
       "114273                5.0  \n",
       "114275                4.0  \n",
       "\n",
       "[63336 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=[\"origin_port\" , \"order_id\" , \"logistic_hub\" , \"customer\", \"late_order\", \"3pl\", \"customs_procedures\"]) # Data represented in the clustermap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We define X and y :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"late_order\",\"order_id\",\"product_id\"])\n",
    "y = data[\"late_order\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We then proceed to scale X and encode the necessary values for both X and y. For example, True and False and y become 1 and 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=MassLabelEncoding(X)\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that our preprocessing is done, we can proceed with the train_test_split function and begin our model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to choose a random forest classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our score is therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the classification : 85.96 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of the classification : \" + str( round(clf.fit(X_train,y_train).score(X_test,y_test)*100,2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can analyze the importance of each of our features by looking at the following graph** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=pd.DataFrame(X)\n",
    "\n",
    "features= list(X.columns)\n",
    "start_time = time.time()\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "forest_importances = pd.Series(importances, index=features)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can make the deduction that we can reduce our dataset by removing some features that are unnecessary, keeping therefore most of the information and improving the efficiency of our algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Comparing with another model\n",
    "\n",
    "We can also challenge our previous model by using an XGBoost Classifier, and see what output we can get out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the classification : 86.74 %\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier()\n",
    "print(\"Score of the classification : \" + str( round(xgb.fit(X_train,y_train).score(X_test,y_test)*100,2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Improving our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to use a custom version of GridSearch in order to look for the best parameters for our classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_early_stopping(\n",
    "    scores: Union[list, np.ndarray],\n",
    "    metric: str,\n",
    "    stopping_rounds: int=4,\n",
    "    stopping_tolerance: float=0.01,\n",
    "    max_runtime_sec: int=None,\n",
    "    start_time: pd.Timestamp=None) -> bool:\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if early stopping condition is met.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    scores: list, np.ndarray\n",
    "        Scores used to evaluate early stopping conditions.\n",
    "        \n",
    "    metric: str\n",
    "        Metric which scores referes to. Used to determine if higher score\n",
    "        means a better model or the opposite.\n",
    "        \n",
    "    stopping_rounds: int, default 4\n",
    "        Number of consecutive rounds without improvement needed to stop\n",
    "        the training.\n",
    "    \n",
    "    stopping_tolerance: float, default 0.01\n",
    "        Minimum percentage of positive change between two consecutive rounds\n",
    "        needed to consider it as an improvement.\n",
    "    \n",
    "    max_runtime_sec: int, default `None`\n",
    "        Maximum allowed runtime in seconds for model training. `None` means unlimited.\n",
    "    \n",
    "    start_time: pd.Timestamp, default `None`\n",
    "        Time when training started. Used to determine if `max_runtime_sec` has been\n",
    "        reached.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    bool:\n",
    "        `True` if any condition needed for early stopping is met. `False` otherwise.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    Example of early stopping:\n",
    "        \n",
    "    Stop after 4 rounds without an improvement of 1% or higher: `stopping_rounds` = 4,\n",
    "    `stopping_tolerance` = 0.01, `max_runtime_sec` = None.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    allowed_metrics = ['accuracy', 'auc', 'f1', 'mse', 'mae', 'squared_error',\n",
    "                       'absolute_error']\n",
    "    \n",
    "    if metric not in allowed_metrics:\n",
    "        raise Exception(\n",
    "                f\"`metric` argument must be one of: {allowed_metrics}. \"\n",
    "                f\"Got {metric}\"\n",
    "        )\n",
    "    \n",
    "    if isinstance(scores, list):\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "    if max_runtime_sec is not None:\n",
    "        \n",
    "        if start_time is None:\n",
    "            start_time = pd.Timestamp.now()\n",
    "            \n",
    "        runing_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "        \n",
    "        if runing_time > max_runtime_sec:\n",
    "            logging.debug(\n",
    "                f\"Reached maximum time for training ({max_runtime_sec} seconds). \"\n",
    "                f\"Early stopping activated.\"\n",
    "            )\n",
    "            return True\n",
    "        \n",
    "    if len(scores) < stopping_rounds:\n",
    "        return False\n",
    "    \n",
    "    if metric in ['accuracy', 'auc', 'f1']:\n",
    "        # The higher the metric, the better\n",
    "        diff_scores = scores[1:] - scores[:-1]\n",
    "        improvement = diff_scores / scores[:-1]\n",
    "        \n",
    "    if metric in ['mse', 'mae', 'squared_error', 'absolute_error']:\n",
    "        # The lower the metric, the better\n",
    "        \n",
    "        # scores = -1 * scores \n",
    "        # diff_scores = scores[:-1] - scores[1:]\n",
    "        # improvement = diff_scores / scores[1:]\n",
    "        diff_scores = scores[1:] - scores[:-1]\n",
    "        improvement = diff_scores / scores[:-1]\n",
    "        improvement = -1 * improvement\n",
    "        \n",
    "    improvement = np.hstack((np.nan, improvement))\n",
    "    logging.debug(f\"Improvement: {improvement}\")\n",
    "    \n",
    "    if (improvement[-stopping_rounds:] < stopping_tolerance).all():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "def fit_RandomForest_early_stopping(\n",
    "    model: Union[RandomForestClassifier, RandomForestRegressor],\n",
    "    X: Union[np.ndarray, pd.core.frame.DataFrame],\n",
    "    y: np.ndarray,\n",
    "    metric: str,\n",
    "    positive_class: int=1,\n",
    "    score_tree_interval: int=None,\n",
    "    stopping_rounds: int=4,\n",
    "    stopping_tolerance: float=0.01,\n",
    "    max_runtime_sec: int=None) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit a RandomForest model until an early stopping condition is met or\n",
    "    `n_estimatos` is reached.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    model: RandomForestClassifier, RandomForestRegressor\n",
    "        Model to be fitted.\n",
    "        \n",
    "    X: np.ndarray, pd.core.frame.DataFrame\n",
    "        Training input samples. \n",
    "    \n",
    "    y: np.ndarray, pd.core.frame.DataFrame\n",
    "        Target value of the input samples. \n",
    "    \n",
    "    scores: list, np.ndarray\n",
    "        Scores used to evaluate early stopping conditions.\n",
    "        \n",
    "    metric: str\n",
    "        Metric used to generate the score. Used to determine if higher score\n",
    "        means a better model or the opposite.\n",
    "        \n",
    "    score_tree_interval: int, default `None`\n",
    "        Score the model after this many trees. If `None`, the model is scored after\n",
    "        `n_estimators` / 10.\n",
    "        \n",
    "    stopping_rounds: int\n",
    "        Number of consecutive rounds without improvement needed to stop the training.\n",
    "    \n",
    "    stopping_tolerance: float, default 0.01\n",
    "        Minimum percentage of positive change between two consecutive rounds\n",
    "        needed to consider it as an improvement. \n",
    "    \n",
    "    max_runtime_sec: int, default `None`\n",
    "        Maximum allowed runtime in seconds for model training. `None` means unlimited.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    oob_scores: np.ndarray\n",
    "        Out of bag score for each scoring point.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if score_tree_interval is None:\n",
    "        score_tree_interval = int(model.n_estimators / 10)\n",
    "        \n",
    "    allowed_metrics = ['accuracy', 'auc', 'f1', 'mse', 'mae', 'squared_error',\n",
    "                       'absolute_error']\n",
    "    \n",
    "    if metric not in allowed_metrics:\n",
    "        raise Exception(\n",
    "                f\"`metric` argument must be one of: {allowed_metrics}. \"\n",
    "                f\"Got {metric}\"\n",
    "        )\n",
    "    \n",
    "    if not model.oob_score:\n",
    "        model.set_params(oob_score=True)\n",
    "        \n",
    "    start_time = pd.Timestamp.now()\n",
    "    oob_scores = []\n",
    "    scoring_points = np.arange(0, model.n_estimators + 1, score_tree_interval)[1:]\n",
    "    scoring_points = np.hstack((1, scoring_points))\n",
    "    \n",
    "    metrics = {\n",
    "        'auc' : roc_auc_score,\n",
    "        'accuracy' : accuracy_score,\n",
    "        'f1': f1_score,\n",
    "        'mse': mean_squared_error,\n",
    "        'squared_error': mean_squared_error,\n",
    "        'mae': mean_absolute_error,\n",
    "        'absolute_error': mean_absolute_error,        \n",
    "    }\n",
    "    \n",
    "    for i, n_estimators in enumerate(scoring_points):\n",
    "        \n",
    "        logging.debug(f\"Training with n_stimators: {n_estimators}\")\n",
    "        model.set_params(n_estimators=n_estimators)\n",
    "        model.fit(X=X, y=y)\n",
    "        \n",
    "        if metric == 'auc':\n",
    "            oob_predictions = model.oob_decision_function_[:, positive_class]\n",
    "            # If n_estimators is small it might be possible that a data point\n",
    "            # was never left out during the bootstrap. In this case,\n",
    "            # oob_decision_function_ might contain NaN.\n",
    "            oob_score = metrics[metric](\n",
    "                            y_true=y[~np.isnan(oob_predictions)],\n",
    "                            y_score=oob_predictions[~np.isnan(oob_predictions)]\n",
    "                        )\n",
    "        else:\n",
    "            oob_predictions = model.oob_decision_function_\n",
    "            oob_predictions = np.argmax(oob_predictions, axis=1)\n",
    "            oob_score = metrics[metric](\n",
    "                            y_true=y[~np.isnan(oob_predictions)],\n",
    "                            y_score=oob_predictions[~np.isnan(oob_predictions)]\n",
    "                        )\n",
    "            \n",
    "        oob_scores.append(oob_score)\n",
    "        \n",
    "        early_stopping = check_early_stopping(\n",
    "                            scores             = oob_scores,\n",
    "                            metric             = metric,\n",
    "                            stopping_rounds    = stopping_rounds,\n",
    "                            stopping_tolerance = stopping_tolerance,\n",
    "                            max_runtime_sec    = max_runtime_sec,\n",
    "                            start_time         = start_time\n",
    "                         )    \n",
    "        \n",
    "        if early_stopping:\n",
    "            logging.debug(\n",
    "                f\"Early stopping activated at round {i + 1}: n_estimators = {n_estimators}\"\n",
    "            )\n",
    "            break\n",
    "        \n",
    "    logging.debug(f\"Out of bag score = {oob_scores[-1]}\")\n",
    "    \n",
    "    return np.array(oob_scores), scoring_points[:len(oob_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gridsearch_RandomForestClassifier(\n",
    "    model: RandomForestClassifier,\n",
    "    X: Union[np.ndarray, pd.core.frame.DataFrame],\n",
    "    y: np.ndarray,\n",
    "    metric: str,\n",
    "    param_grid: dict,\n",
    "    positive_class: int=1,\n",
    "    score_tree_interval: int=None,\n",
    "    stopping_rounds: int=5,\n",
    "    stopping_tolerance: float=0.01,\n",
    "    model_max_runtime_sec: int=None,\n",
    "    max_models: int=None,\n",
    "    max_runtime_sec: int=None,\n",
    "    return_best: bool=True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    '''\n",
    "    Grid search for RandomForestClassifier model based on out-of-bag metric and \n",
    "    early stopping for each model fit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    model: RandomForestClassifier\n",
    "        Model to search over.\n",
    "           \n",
    "    X: np.ndarray, pd.core.frame.DataFrame\n",
    "        The training input samples. \n",
    "    \n",
    "    y: np.ndarray, pd.core.frame.DataFrame\n",
    "        The target of input samples. \n",
    "    \n",
    "    scores: list, np.ndarray\n",
    "        Scores used to evaluate early stopping conditions.\n",
    "        \n",
    "    metric: str\n",
    "        Metric used to generate the score. I is used to determine if higher score\n",
    "        means a better model or the opposite.\n",
    "        \n",
    "    score_tree_interval: int, default `None`\n",
    "        Score the model after this many trees. If `None`, the model is scored after\n",
    "        `n_estimators` / 10.\n",
    "        \n",
    "    stopping_rounds: int\n",
    "        Number of consecutive rounds without improvement needed to stop the training.\n",
    "    \n",
    "    stopping_tolerance: float, default 0.01\n",
    "        Minimum percentage of positive change between two consecutive rounds\n",
    "        needed to consider it as an improvement. \n",
    "    \n",
    "    model_max_runtime_sec: int, default `None`\n",
    "        Maximum allowed runtime in seconds for model training. `None` means unlimited.\n",
    "        \n",
    "    max_models: int, default `None`\n",
    "        Maximum number of models trained during the search.\n",
    "    \n",
    "    max_runtime_sec: int, default `None`\n",
    "        Maximum number of seconds for the search.\n",
    "        \n",
    "    return_best : bool\n",
    "        Refit model using the best found parameters on the whole data.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    \n",
    "    results: pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    results = {'params': [], 'oob_metric': []}\n",
    "    start_time = pd.Timestamp.now()\n",
    "    history_scores = {}\n",
    "    history_scoring_points = np.array([], dtype = int)\n",
    "    param_grid = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    if not model.oob_score:\n",
    "        model.set_params(oob_score=True)\n",
    "    \n",
    "    if max_models is not None and max_models < len(param_grid):\n",
    "        param_grid = np.random.choice(param_grid, max_models)\n",
    "\n",
    "    for params in tqdm.tqdm(param_grid):\n",
    "        \n",
    "        if max_runtime_sec is not None:\n",
    "            runing_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "            if runing_time > max_runtime_sec:\n",
    "                logging.info(\n",
    "                    f\"Reached maximum time for GridSearch ({max_runtime_sec} seconds). \"\n",
    "                    f\"Search stopped.\"\n",
    "                )\n",
    "                break   \n",
    "        \n",
    "        model.set_params(**params)\n",
    "\n",
    "        oob_scores, scoring_points = fit_RandomForest_early_stopping(\n",
    "                                        model = clone(model), # Clone to avoid modification of n_estimators\n",
    "                                        X = X,\n",
    "                                        y = y,\n",
    "                                        metric = metric,\n",
    "                                        positive_class      = positive_class,\n",
    "                                        score_tree_interval = score_tree_interval,\n",
    "                                        stopping_rounds     = stopping_rounds,\n",
    "                                        stopping_tolerance  = stopping_tolerance,\n",
    "                                        max_runtime_sec     = model_max_runtime_sec\n",
    "                                     )\n",
    "      \n",
    "        history_scoring_points = np.union1d(history_scoring_points,  scoring_points)        \n",
    "        history_scores[str(params)] = oob_scores\n",
    "        params['n_estimators'] = scoring_points[-1]\n",
    "        results['params'].append(params)\n",
    "        results['oob_metric'].append(oob_scores[-1])\n",
    "        logging.debug(f\"Modelo: {params} \\u2713\")\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    history_scores = pd.DataFrame(\n",
    "                            dict([(k, pd.Series(v)) for k,v in history_scores.items()])\n",
    "                         )\n",
    "    history_scores['n_estimators'] = history_scoring_points\n",
    "    \n",
    "    if metric in ['accuracy', 'auc', 'f1']:\n",
    "        results = results.sort_values('oob_metric', ascending=False)\n",
    "    else:\n",
    "        results = results.sort_values('oob_metric', ascending=True)\n",
    "        \n",
    "    results = results.rename(columns = {'oob_metric': f'oob_{metric}'})\n",
    "    \n",
    "    if return_best:\n",
    "        best_params = results['params'].iloc[0]\n",
    "        print(\n",
    "            f\"Refitting mode using the best found parameters and the whole data set: \\n {best_params}\"\n",
    "        )\n",
    "        \n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X=X, y=y)\n",
    "        \n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    results = results.drop(columns = 'params')\n",
    "    \n",
    "    return results, history_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "             'max_depth'   : [3, 10, 15, 20, 35 , 50],\n",
    "             'max_features': ['sqrt', 'log2'],\n",
    "             'ccp_alpha': [0, 0.01]\n",
    "            }\n",
    "clf= RandomForestClassifier(\n",
    "            n_estimators = 100,\n",
    "            oob_score    = True,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 0\n",
    "        )\n",
    "\n",
    "gridsearch =0 # =1 if we want to do the gridsearch (requires 1 or 2 minutes for execution)\n",
    "\n",
    "if gridsearch ==1: \n",
    "\n",
    "    start = pd.Timestamp.now()\n",
    "\n",
    "    results, history = custom_gridsearch_RandomForestClassifier(\n",
    "                            model                 = clf,\n",
    "                            X                     = X,\n",
    "                            y                     = y,\n",
    "                            metric                = 'auc',\n",
    "                            param_grid            = param_grid,\n",
    "                            positive_class        = 1,\n",
    "                            score_tree_interval   = 50,\n",
    "                            stopping_rounds       = 4,\n",
    "                            stopping_tolerance    = 0.01,\n",
    "                            model_max_runtime_sec = None,\n",
    "                            max_models            = None,\n",
    "                            max_runtime_sec       = None,\n",
    "                            return_best           = True\n",
    "                          )\n",
    "\n",
    "    end = pd.Timestamp.now()\n",
    "\n",
    "    print(\"Duration : \", end - start)\n",
    "\n",
    "#Returned value : {'ccp_alpha': 0, 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are now going to use the output of this gridsearch as a parameter for our classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(**{'criterion' : 'entropy' , 'ccp_alpha': 0, 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"origin_port\", \"3pl\", \"customs_procedures\", \"logistic_hub\", \"distance_origin_hub\",\"product_id\"],inplace=True)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "X = data.drop(columns=[\"late_order\",\"order_id\"])\n",
    "y = data[\"late_order\"]\n",
    "\n",
    "X=MassLabelEncoding(X)\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the classification : 86.01 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of the classification : \" + str( round(clf.fit(X_train,y_train).score(X_test,y_test)*100,2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We therefore notice a slight improvement of our model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our model only makes sense if we apply it on the same \"type\" of data, we therefore need to make the same modifications to the test.csv dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.55801758, -0.10701816, -0.30119298,  1.38288656,  1.09383396],\n",
       "       [-1.28576687, -3.58577962, -0.86966926,  2.15166353, -1.8726682 ],\n",
       "       [ 0.80385551,  0.31865307,  0.21974687, -0.80472183,  1.09383396],\n",
       "       ...,\n",
       "       [ 0.43509862, -0.01894825, -0.5256005 , -0.89425029,  1.09383396],\n",
       "       [ 0.43509862,  1.16999554, -0.45524204, -0.34734819, -0.09276691],\n",
       "       [-0.79409102, -0.32719294, -0.31141627, -1.73503928,  0.50053352]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test.copy()\n",
    "\n",
    "distance_origin_hub= []\n",
    "distance_hub_customer = []\n",
    "\n",
    "for i in range(len(data)): \n",
    "    try : \n",
    "        distance_origin_hub.append(float(cities_data[(cities_data[\"city_from_name\"] == data[\"origin_port\"][i])& (cities_data[\"city_to_name\"] == data[\"logistic_hub\"][i])][\"distance\"]))\n",
    "    except:\n",
    "        distance_origin_hub.append(np.nan)\n",
    "    try : \n",
    "        distance_hub_customer.append(float(cities_data[(cities_data[\"city_from_name\"] == data[\"logistic_hub\"][i] )& (cities_data[\"city_to_name\"] == data[\"customer\"][i])][\"distance\"]))\n",
    "    except:\n",
    "        distance_hub_customer.append(np.nan)\n",
    "        \n",
    "data[\"distance_origin_hub\"]=distance_origin_hub\n",
    "data[\"distance_hub_customer\"] = distance_hub_customer           \n",
    "\n",
    "data=data.join(product_attributes.set_index(\"product_id\"), on = \"product_id\")\n",
    "\n",
    "data.replace([\"BCN\",\"ATHENAS\"],[\"Barcelona\", \"Athens\"],inplace=True) #Replacing double values\n",
    "\n",
    "#data.dropna(inplace=True) # removing all values, imputing values here would be irrelevant\n",
    "\n",
    "data.drop(columns=[\"origin_port\", \"3pl\", \"customs_procedures\", \"logistic_hub\", \"distance_origin_hub\",\"product_id\"],inplace=True)\n",
    "\n",
    "X = data.drop(columns=[\"order_id\"])\n",
    "\n",
    "X=MassLabelEncoding(X)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also need, in this case, to impute values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28563.000000</td>\n",
       "      <td>28563.000000</td>\n",
       "      <td>28563.000000</td>\n",
       "      <td>28563.000000</td>\n",
       "      <td>28563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.460281</td>\n",
       "      <td>484.290901</td>\n",
       "      <td>966.217380</td>\n",
       "      <td>1263.192137</td>\n",
       "      <td>3.159262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.135584</td>\n",
       "      <td>68.128888</td>\n",
       "      <td>531.843906</td>\n",
       "      <td>513.454367</td>\n",
       "      <td>1.685775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>34.429100</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>558.146400</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>485.000000</td>\n",
       "      <td>847.308200</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>1309.179000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>2768.966300</td>\n",
       "      <td>2876.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4\n",
       "count  28563.000000  28563.000000  28563.000000  28563.000000  28563.000000\n",
       "mean      13.460281    484.290901    966.217380   1263.192137      3.159262\n",
       "std        8.135584     68.128888    531.843906    513.454367      1.685775\n",
       "min        0.000000    108.000000     34.429100    136.000000      0.000000\n",
       "25%        6.000000    447.000000    558.146400    900.000000      2.000000\n",
       "50%       14.000000    485.000000    847.308200   1230.000000      3.000000\n",
       "75%       20.000000    522.000000   1309.179000   1627.000000      5.000000\n",
       "max       27.000000    983.000000   2768.966300   2876.000000      5.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "X=imp.fit_transform(X)\n",
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>late_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0e364fa5c795</td>\n",
       "      <td>0.141132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3ef49bd5a55b</td>\n",
       "      <td>0.042655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9ab5b9685bd5</td>\n",
       "      <td>0.177090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfce5b4fc4fa</td>\n",
       "      <td>0.542308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d94453ec8ec5</td>\n",
       "      <td>0.389478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28558</th>\n",
       "      <td>d268acf6459e</td>\n",
       "      <td>0.150236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28559</th>\n",
       "      <td>1aefc30b0eb3</td>\n",
       "      <td>0.157927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28560</th>\n",
       "      <td>646a2e50e170</td>\n",
       "      <td>0.094922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28561</th>\n",
       "      <td>bf5177549be9</td>\n",
       "      <td>0.089954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28562</th>\n",
       "      <td>525dafc0ad62</td>\n",
       "      <td>0.139098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id  late_order\n",
       "0      0e364fa5c795    0.141132\n",
       "1      3ef49bd5a55b    0.042655\n",
       "2      9ab5b9685bd5    0.177090\n",
       "3      bfce5b4fc4fa    0.542308\n",
       "4      d94453ec8ec5    0.389478\n",
       "...             ...         ...\n",
       "28558  d268acf6459e    0.150236\n",
       "28559  1aefc30b0eb3    0.157927\n",
       "28560  646a2e50e170    0.094922\n",
       "28561  bf5177549be9    0.089954\n",
       "28562  525dafc0ad62    0.139098\n",
       "\n",
       "[28563 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=clf.predict_proba(X)\n",
    "y_final=[x[1] for x in y]\n",
    "test[\"late_order\"]=y_final\n",
    "df_final=test.drop(columns =[ \"origin_port\" , \"3pl\", \"customs_procedures\" , \"logistic_hub\" , \"customer\", \"product_id\",\"units\"])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exporting to csv..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export=0\n",
    "if Export==1 :\n",
    "    df_final.to_csv(\"submission_kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
